---
Title: Facebook Trustworthiness Score
Template: LeafPage
---
#Facebook Trustworthiness Score

On August 21 2018, the Washington Post revealed that over the last year Facebook has developed a rating system to rate users on a scale from 0 to 1 that determines if they have a good or bad reputation. Facebook confirmed this to The Sun. This score is completely hidden from users. As stated by Tessa Lyons, the product manaer who is in charge of fighting misinformation, Facebook has developed this in an effort to fight against *fake news*. 

In order to calculate this score, Facebook is tracking users' behaviour across the website. Facebook told The Sun how this system works:
  - In order to fight against fake news, Facebook has started to use machine learning systems in order to predict articles that human fact-checkers should review;
  - They have now developed a process that protects against people who flag news as fake simply people they do not agree with it;
  - One of the indicators used in this process is how people report articles as false. For example, if someone gave Facebook feedback that an article was false and this was confirmed by a human fact-checker, then that person's future feedback would be weighted more positively;
  - This is all reflected in an **invisible score or rating**.

Online commentators are already comparing this the the [Chinese social credit system](http://cueimps.soc.srcf.net/course/course/credit-scores/Social_Credit_Scores/china). 

As highlighted by Claire Wardle, director of First Draft (a research lab within the Harvard Kennedy School), “not knowing how [Facebook is] judging us is what makes us uncomfortable”. However, ironically, they can't tell us how we're being judged because if they do, the system can be gamed.

Samidh Chakrabarti, who is in charge of civic engagement at Facebook, states that Facebook users are "professionalised, and constantly try to game the system". This score is an attempt to fight against this and accurately pinpoint *fake news* articles.

So, Facebook is now determining how *trustworthy* we are, using data from how we interact with their website. Worst of all, we have no ability to know what our individual score is. So far, it is only being used as one signal among many that the company feeds into more algorithms to help it decide which stories should be reviewed. However, this number can be applied to many other areas, and as a result Facebook can sell it to, for example, credit scorers, employers, or even dating apps. As well as a huge breach in our privacy, surely legally this is not correct as if we dont know what our score is, let alone what Facebook is using to calculate this score, **how can we possibly challenge it?** 

Another problem is the protection of this data. Say this score is stored with an accuracy of 3 decimal places. This data will be around 2TB, which is enough to fit on a memory stick. As a result, a data leak is extremely possible. And, what happens if this data leaks? This information could be used against individuals, or even sold to third parties to but used in scoring models. Although this is all a hypothesis, we cannot neglect the possibility of such an event in order to take measures to make sure it doesn't happen. 

##References

[1] Elizabeth Dwoskin. Facebook is rating the trustworthiness of its users on a scale from zero to 1. *The Washington Post*, August 2018.

[2] Sean Keach. Facebook has TRUST ratings for users - but it won't tell you your score. *The Sun,* August 2018.
