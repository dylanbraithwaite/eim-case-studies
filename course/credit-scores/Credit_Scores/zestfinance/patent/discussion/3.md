---
Title: Developing a Final Model Through Analysis of Training Data and Feature Selection
Template: LeafPage
---

#Developing a Final Model Through Analysis of Training Data and Feature Selection

[Insert video of people discussing issue]

---

*Include information below*

Not all inputs will be relevant. In fact, many are likely to be discarded as the system learns what is relevant to the target variable and what isn't. As can be gleaned from the ZestFinance patent, their feature selection process is not uniformly automated and the company selects the most relevant meta-variables in one of two ways:

	1. a data analyst curates, or manually determines, which meta-variables are significant, drawing from past experiences and observations of the applicant pool. 
	
	2. statistical algorithms are used to automatically identify the most significant metavariables. 

As a result, it isn't possible to see which of ZestFinance's metavariables have come out as the most significant, how they are calculated, or whether they accurately reflect creditworthiness. 

Additionally, the way in which the data scientist develops and refines the final credit-scoring model can cause issues with transparency and the ability for a consumer to challenge scores. This is because the process is so complex it would be very hard to understand and determine if inaccuracies in the data have negatively influenced their score. 

The machine-learning and feature selection process may also result in models that have some bias and that may inadvertently factor in characteristics that it shouldn't, such as race. This is due to the fact that characteristics of the consumer, such as their use of technology, shopping habits, social-media practices, etc. likely vary by race. For example, 30% of whites use their mobile phone as their only form of Internet connection, compared to around 47% of Latinos and 38% of blacks. As a result, when combined with other infomation, the way people use their mobiles and the Internet could be used as a proxy for race.

Even when data miners are careful, they can still produce models that unintentionally pick out proxy variables for protected classes. 

A possible effect of this *social credit score* is social segregation. In order to boost their credit score, a user may try to 'clean' their social media pages by, for example, unfriending certain people who have lower credit scores or refraining from liking pages that may give a 'bad impression' about them. 

>*"Those from disadvantaged backgrounds would interact only with users who, likewise, have not been able to break free of the cycle of poverty; Ivy League alumni would only allow themselves to be associated with similarly elite peers; an executive wishing to virtually follow an organization committed to helping poor families is likely to avoid creating a traceable connection between herself and the unfortunate, and for similar reasons may be reluctant to "like" the business page for her best friendâ€™s debt refinancing company."* - Packin and Lev-Aretz (2016)

Studies highlight that online social networks allow new social ties to form, even with complete strangers. As a result, the consequences of people perfecting their social media profile will most likely extend beyond "virtual realms". 

>*"Widespread online segregation caused by social financial ranking could also legitimize the idea that people should be valued by their economic standing, and that friendships should accordingly occur only among homogenous groups."* - Packin and Lev-Aretz (2016) 

---

##References

[1] Douglas C. Merrill, Shawn M. Budde, John W.L. Merrill, Lingyun Gu, and James P. McGuire. System and method for building and validating a credit scoring function, January 2015.

[2] Daria Kuss and Mark Griffiths. *Online Social Networking and Addiction - A Review of the Psychological Literature,* volume 8. September 2011. 

[3] Nizan Geslevich Packin and Yafit Lev-Aretz. On Social Credit and the Right to be Unnetworked. *Columbia Business Law Review,* 339, February 2016. 

[4] Persis Yu, Jillian McLaughlin, and Marina Levy. Big Data, a Big Disappointment for Socring Consumer Creditworthiness. Technical report, National Consumer Law Center, March 2014. 



