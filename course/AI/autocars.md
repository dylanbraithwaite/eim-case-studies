---

Title: Self Driving Cars
Template: ListSubPages

---



# Self Driving Cars

The concept of the autonomous vehicle has been around for a long time; examples such as aircraft autopilot (1933) or cruise control (1945) have been in existence for decades [1]. However, the world's firms are currently racing to build a fully autonomous car, and this involves the use of artificial intelligence. 

Companies including Google, Uber, Tesla and General Motors are in a race to get autonomous vehicles into public use [2]. It is expected that these cars will be in the hands of the public in just a few years. However, in the development of self-driving cars, many accidents have occurred. One prominent example of this occurred in March 2018, when an autonomous car killed a pedestrian for the first time. The event happened while an Uber autonomous car was undergoing testing in Tempe, Arizona. One of the main reasons for the crash was that the vehicle didn't identify Elaine Herzberg in time; the vehicle only realised that the brakes needed to be applied 1.3 seconds before the impact occurred. Another reason for the crash was that the car was not fully autonomous. The autonomous emergency braking had been disabled to "reduce the potential for erratic vehicle behaviour," [3] with the idea that the human in the car would brake suddenly should the need arise. (One should note, however, that the conditions surrounding the crash – the pitch-black of night, the dark clothing of the woman crossing the road without lights – leave the blame for the incident deeply ambiguous. At any rate, the dashcam footage suggests that almost any human driver could not have avoided the collision if placed in the same situation – though certainly improvements are possible.)

This example encaptures many of the ethical issues arising from autonomous cars. We will discuss just a few of them. One of the key issues demonstrated here is the danger of semi-autonomous vehicles. Humans aren't always aware of the responsibility they have and, as in this case, are likely to underestimate the how much attention they need to pay to the surroundings [4]. There is also the problem that multiple (primarily human) failings led to a disastrous outcome. The individual failings wouldn't necessarily have resulted in the same outcome, but the errors compounded to produce a devastating but unpredictable event. This shows how careful we need to be about new technology, and maybe a 'race' to get autonomous vehicles into the public domain isn't the safest way to go about this technological advancement. 

### References
[1] [A Brief History of Autonomous Vehicle Technology](https://www.wired.com/brandlab/2016/03/a-brief-history-of-autonomous-vehicle-technology/) *Wired,* March 2016.

[2] [Who's Winning the Self-Driving Car Race](https://www.bloomberg.com/news/features/2018-05-07/who-s-winning-the-self-driving-car-race) *Bloomberg,* May 2018

[3] [Uber resumes testing for autonomous cars in 'manual mode'](https://phys.org/news/2018-07-uber-resumes-autonomous-cars-manual.html) *phys.org,* July 2018

[4] [Why Uber's self-driving car killed a pedestrian](https://www.economist.com/the-economist-explains/2018/05/29/why-ubers-self-driving-car-killed-a-pedestrian) *The Economist,* May 2018
